{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset analyse",
   "id": "7c6f58b956696c16"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-17T14:23:30.009449Z",
     "start_time": "2025-04-17T14:23:29.990331Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.constants import precision\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"graduation_train.csv\")\n",
    "\n",
    "for colum in df.columns:\n",
    "    df = df[df[colum] != \"\"]\n",
    "\n",
    "df[\"curricular_units_1st_sem_grade_rounded\"] = df[\"curricular_units_1st_sem_grade\"].round(0)\n",
    "df[\"curricular_units_2nd_sem_grade_rounded\"] = df[\"curricular_units_2nd_sem_grade\"].round(0)\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "# df = df[df[\"InvoiceDate\"] < pd.Timestamp('today')]#remove purchases in the future\n",
    "# df = df[df.Invoice.str.isnumeric()]#remove all Invoices that are not numbers\n",
    "# #df = df[df.StockCode.str.isnumeric()]#remove all StockCodes that are not numbers not all stock codes are intigers\n",
    "# df = df[pd.to_numeric(df.Price, errors='coerce').notnull()]\n",
    "# df[\"Customer ID\"] = pd.to_numeric(df[\"Customer ID\"], errors=\"raise\", downcast='integer')\n",
    "# df = df[pd.to_numeric(df[\"Customer ID\"], errors='coerce', downcast='integer').notnull()]\n",
    "# df = df[df.duplicated(subset=[\"StockCode\", \"Description\"], keep=False)]#remove inconsistent row between stockcode and description\n",
    "#\n",
    "# print(df)\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/ensemble.html\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Report",
   "id": "8decfdc7c279e13f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:23:30.067470Z",
     "start_time": "2025-04-17T14:23:30.063818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, RocCurveDisplay\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "def report(title, test_items, pass_df, clf):\n",
    "    print(f\"==={title}===\")\n",
    "    predictions = clf.predict(test_items)\n",
    "    y_pred_proba = clf.predict_proba(test_items)[:, 1]  # Probabilities for AUC\n",
    "\n",
    "    # 1. Accuracy\n",
    "    accuracy = accuracy_score(pass_df[\"target\"], predictions)\n",
    "\n",
    "    # 2. AUC\n",
    "    auc = roc_auc_score(pass_df[\"target\"], y_pred_proba)\n",
    "\n",
    "    # 3. Precision & Recall for both classes\n",
    "    precision_0 = precision_score(pass_df[\"target\"], predictions, pos_label=0)\n",
    "    recall_0 = recall_score(pass_df[\"target\"], predictions, pos_label=0)\n",
    "    precision_1 = precision_score(pass_df[\"target\"], predictions, pos_label=1)\n",
    "    recall_1 = recall_score(pass_df[\"target\"], predictions, pos_label=1)\n",
    "\n",
    "    # 4. Full classification report (optional but useful)\n",
    "    report = classification_report(pass_df[\"target\"], predictions)\n",
    "\n",
    "    # Output everything\n",
    "    print(\"=== Metrics Report ===\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Precision (Class 0): {precision_0:.4f}\")\n",
    "    print(f\"Recall (Class 0):    {recall_0:.4f}\")\n",
    "    print(f\"Precision (Class 1): {precision_1:.4f}\")\n",
    "    print(f\"Recall (Class 1):    {recall_1:.4f}\")\n",
    "    print(\"\\nFull Classification Report:\")\n",
    "    print(report)\n",
    "\n"
   ],
   "id": "bb8decab0c8c7ee0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## load train data\n",
   "id": "d1b3f554aecd019a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:23:30.125847Z",
     "start_time": "2025-04-17T14:23:30.122913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "colums = [\"curricular_units_1st_sem_grade_rounded\", \"curricular_units_1st_sem_evaluations\", \"curricular_units_1st_sem_approved\",\n",
    "          \"curricular_units_2nd_sem_grade_rounded\", \"curricular_units_2nd_sem_evaluations\", \"curricular_units_2nd_sem_approved\",\n",
    "          \"course\", \"previous_qualification\", \"special_needs\"]\n",
    "\n",
    "X = train_df[colums].values.tolist()\n",
    "Y = list(train_df[\"target\"])"
   ],
   "id": "55a02baae38204ac",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## decision_tree",
   "id": "6c50bb92bcab84f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:23:30.357488Z",
     "start_time": "2025-04-17T14:23:30.185335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "decision_tree_classifier = tree.DecisionTreeClassifier()\n",
    "clf = decision_tree_classifier.fit(X, Y)\n",
    "\n",
    "dot_data = tree.export_graphviz(\n",
    "    clf,\n",
    "    out_file=None,\n",
    "    feature_names=colums,\n",
    "    class_names=[\"Passed\", \"Drop out\"],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True\n",
    ")\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"decision_tree\")  # Saves as 'decision_tree.pdf'\n",
    "#graph.view()  # Opens the tree\n",
    "\n",
    "report(\"decision_tree\", test_df[colums].values.tolist(), test_df, decision_tree_classifier)"
   ],
   "id": "b62abc5cd51d7d9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===decision_tree===\n",
      "=== Metrics Report ===\n",
      "Accuracy: 0.8296\n",
      "AUC: 0.8418\n",
      "Precision (Class 0): 0.7763\n",
      "Recall (Class 0):    0.7727\n",
      "Precision (Class 1): 0.8619\n",
      "Recall (Class 1):    0.8643\n",
      "\n",
      "Full Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77       220\n",
      "           1       0.86      0.86      0.86       361\n",
      "\n",
      "    accuracy                           0.83       581\n",
      "   macro avg       0.82      0.82      0.82       581\n",
      "weighted avg       0.83      0.83      0.83       581\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NearestNeighbor",
   "id": "e15908b97c2aa8bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:23:30.394874Z",
     "start_time": "2025-04-17T14:23:30.364427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "knn_classifier = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=5))]\n",
    ")\n",
    "knn_classifier.fit(X, Y)\n",
    "report(\"decision_tree\", test_df[colums].values.tolist(), test_df, knn_classifier)"
   ],
   "id": "1fa60380cf7b2628",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===decision_tree===\n",
      "=== Metrics Report ===\n",
      "Accuracy: 0.8571\n",
      "AUC: 0.8931\n",
      "Precision (Class 0): 0.8743\n",
      "Recall (Class 0):    0.7273\n",
      "Precision (Class 1): 0.8492\n",
      "Recall (Class 1):    0.9363\n",
      "\n",
      "Full Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.73      0.79       220\n",
      "           1       0.85      0.94      0.89       361\n",
      "\n",
      "    accuracy                           0.86       581\n",
      "   macro avg       0.86      0.83      0.84       581\n",
      "weighted avg       0.86      0.86      0.85       581\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## naive bayes",
   "id": "657231c1d7b9a59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:23:30.421891Z",
     "start_time": "2025-04-17T14:23:30.411010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_classifier = GaussianNB()\n",
    "\n",
    "gnb_classifier.fit(X, Y)\n",
    "\n",
    "report(\"decision_tree\", test_df[colums].values.tolist(), test_df, gnb_classifier)"
   ],
   "id": "e43c7b99716458b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===decision_tree===\n",
      "=== Metrics Report ===\n",
      "Accuracy: 0.8382\n",
      "AUC: 0.8970\n",
      "Precision (Class 0): 0.9038\n",
      "Recall (Class 0):    0.6409\n",
      "Precision (Class 1): 0.8141\n",
      "Recall (Class 1):    0.9584\n",
      "\n",
      "Full Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.64      0.75       220\n",
      "           1       0.81      0.96      0.88       361\n",
      "\n",
      "    accuracy                           0.84       581\n",
      "   macro avg       0.86      0.80      0.82       581\n",
      "weighted avg       0.85      0.84      0.83       581\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ensemble method",
   "id": "a70666b121f41739"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:23:30.489553Z",
     "start_time": "2025-04-17T14:23:30.460145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_classifier = RandomForestClassifier(n_estimators=10)\n",
    "clf_classifier.fit(X, Y)\n",
    "report(\"decision_tree\", test_df[colums].values.tolist(), test_df, clf_classifier)"
   ],
   "id": "b543a5959806ff8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===decision_tree===\n",
      "=== Metrics Report ===\n",
      "Accuracy: 0.8640\n",
      "AUC: 0.9078\n",
      "Precision (Class 0): 0.8439\n",
      "Recall (Class 0):    0.7864\n",
      "Precision (Class 1): 0.8750\n",
      "Recall (Class 1):    0.9114\n",
      "\n",
      "Full Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.81       220\n",
      "           1       0.88      0.91      0.89       361\n",
      "\n",
      "    accuracy                           0.86       581\n",
      "   macro avg       0.86      0.85      0.85       581\n",
      "weighted avg       0.86      0.86      0.86       581\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# clasifier tester",
   "id": "2947736b39c62150"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:33:24.146643Z",
     "start_time": "2025-04-17T14:33:24.094108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from classifier_test_framework import ClassifierTestFramework\n",
    "import pandas as pd\n",
    "\n",
    "colums = [\"curricular_units_1st_sem_grade_rounded\", \"curricular_units_1st_sem_evaluations\", \"curricular_units_1st_sem_approved\",\n",
    "          \"curricular_units_2nd_sem_grade_rounded\", \"curricular_units_2nd_sem_evaluations\", \"curricular_units_2nd_sem_approved\",\n",
    "          \"course\", \"previous_qualification\", \"special_needs\"]\n",
    "\n",
    "classifier_test_framework = ClassifierTestFramework(df, colums)\n",
    "\n",
    "classifier_test_framework.add_classifier(\"DecisionTree\", tree.DecisionTreeClassifier())\n",
    "classifier_test_framework.add_classifier(\"knn\", Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=5))]\n",
    "))\n",
    "classifier_test_framework.add_classifier(\"Naive_bayes\", GaussianNB())\n",
    "classifier_test_framework.add_classifier(\"Ensemble_method\", RandomForestClassifier(n_estimators=10))\n",
    "for key, report in classifier_test_framework.get_results().items():\n",
    "    print(f\"==={key}===\")\n",
    "    print(report)"
   ],
   "id": "73794f61127abed3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DecisionTree': '              precision    recall  f1-score   support\\n\\n           0       0.73      0.81      0.77       219\\n           1       0.88      0.81      0.85       362\\n\\n    accuracy                           0.81       581\\n   macro avg       0.80      0.81      0.81       581\\nweighted avg       0.82      0.81      0.82       581\\n', 'knn': '              precision    recall  f1-score   support\\n\\n           0       0.91      0.79      0.85       219\\n           1       0.88      0.95      0.92       362\\n\\n    accuracy                           0.89       581\\n   macro avg       0.90      0.87      0.88       581\\nweighted avg       0.89      0.89      0.89       581\\n', 'Naive_bayes': '              precision    recall  f1-score   support\\n\\n           0       0.87      0.59      0.70       219\\n           1       0.79      0.94      0.86       362\\n\\n    accuracy                           0.81       581\\n   macro avg       0.83      0.77      0.78       581\\nweighted avg       0.82      0.81      0.80       581\\n', 'Ensemble_method': '              precision    recall  f1-score   support\\n\\n           0       0.78      0.84      0.81       219\\n           1       0.90      0.86      0.88       362\\n\\n    accuracy                           0.85       581\\n   macro avg       0.84      0.85      0.85       581\\nweighted avg       0.86      0.85      0.85       581\\n'}\n",
      "===DecisionTree===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77       219\n",
      "           1       0.88      0.81      0.85       362\n",
      "\n",
      "    accuracy                           0.81       581\n",
      "   macro avg       0.80      0.81      0.81       581\n",
      "weighted avg       0.82      0.81      0.82       581\n",
      "\n",
      "===knn===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85       219\n",
      "           1       0.88      0.95      0.92       362\n",
      "\n",
      "    accuracy                           0.89       581\n",
      "   macro avg       0.90      0.87      0.88       581\n",
      "weighted avg       0.89      0.89      0.89       581\n",
      "\n",
      "===Naive_bayes===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.59      0.70       219\n",
      "           1       0.79      0.94      0.86       362\n",
      "\n",
      "    accuracy                           0.81       581\n",
      "   macro avg       0.83      0.77      0.78       581\n",
      "weighted avg       0.82      0.81      0.80       581\n",
      "\n",
      "===Ensemble_method===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       219\n",
      "           1       0.90      0.86      0.88       362\n",
      "\n",
      "    accuracy                           0.85       581\n",
      "   macro avg       0.84      0.85      0.85       581\n",
      "weighted avg       0.86      0.85      0.85       581\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

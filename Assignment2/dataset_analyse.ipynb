{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset analyse",
   "id": "7c6f58b956696c16"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-11T12:39:18.691264Z",
     "start_time": "2025-04-11T12:39:18.579050Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.constants import precision\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"graduation_train.csv\")\n",
    "\n",
    "for colum in df.columns:\n",
    "    df = df[df[colum] != \"\"]\n",
    "\n",
    "df[\"curricular_units_1st_sem_grade_rounded\"] = df[\"curricular_units_1st_sem_grade\"].round(0)\n",
    "df[\"curricular_units_2nd_sem_grade_rounded\"] = df[\"curricular_units_2nd_sem_grade\"].round(0)\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "# df = df[df[\"InvoiceDate\"] < pd.Timestamp('today')]#remove purchases in the future\n",
    "# df = df[df.Invoice.str.isnumeric()]#remove all Invoices that are not numbers\n",
    "# #df = df[df.StockCode.str.isnumeric()]#remove all StockCodes that are not numbers not all stock codes are intigers\n",
    "# df = df[pd.to_numeric(df.Price, errors='coerce').notnull()]\n",
    "# df[\"Customer ID\"] = pd.to_numeric(df[\"Customer ID\"], errors=\"raise\", downcast='integer')\n",
    "# df = df[pd.to_numeric(df[\"Customer ID\"], errors='coerce', downcast='integer').notnull()]\n",
    "# df = df[df.duplicated(subset=[\"StockCode\", \"Description\"], keep=False)]#remove inconsistent row between stockcode and description\n",
    "#\n",
    "# print(df)\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/ensemble.html\n"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T12:43:53.952514Z",
     "start_time": "2025-04-11T12:43:52.771907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, RocCurveDisplay\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "def report(test_items, pass_df):\n",
    "    predictions = clf.predict(test_items)\n",
    "    y_pred_proba = clf.predict_proba(test_items)[:, 1]  # Probabilities for AUC\n",
    "\n",
    "    # 1. Accuracy\n",
    "    accuracy = accuracy_score(pass_df[\"target\"], predictions)\n",
    "\n",
    "    # 2. AUC\n",
    "    auc = roc_auc_score(pass_df[\"target\"], y_pred_proba)\n",
    "\n",
    "    # 3. Precision & Recall for both classes\n",
    "    precision_0 = precision_score(pass_df[\"target\"], predictions, pos_label=0)\n",
    "    recall_0 = recall_score(pass_df[\"target\"], predictions, pos_label=0)\n",
    "    precision_1 = precision_score(pass_df[\"target\"], predictions, pos_label=1)\n",
    "    recall_1 = recall_score(pass_df[\"target\"], predictions, pos_label=1)\n",
    "\n",
    "    # 4. Full classification report (optional but useful)\n",
    "    report = classification_report(pass_df[\"target\"], predictions)\n",
    "\n",
    "    # Output everything\n",
    "    print(\"=== Metrics Report ===\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Precision (Class 0): {precision_0:.4f}\")\n",
    "    print(f\"Recall (Class 0):    {recall_0:.4f}\")\n",
    "    print(f\"Precision (Class 1): {precision_1:.4f}\")\n",
    "    print(f\"Recall (Class 1):    {recall_1:.4f}\")\n",
    "    print(\"\\nFull Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "\n",
    "\n",
    "colums = [\"curricular_units_1st_sem_grade_rounded\", \"curricular_units_1st_sem_evaluations\", \"curricular_units_1st_sem_approved\",\n",
    "          \"curricular_units_2nd_sem_grade_rounded\", \"curricular_units_2nd_sem_evaluations\", \"curricular_units_2nd_sem_approved\",\n",
    "          \"course\", \"previous_qualification\", \"special_needs\"]\n",
    "\n",
    "X = train_df[colums].values.tolist()\n",
    "Y = list(train_df[\"target\"])\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, Y)\n",
    "\n",
    "dot_data = tree.export_graphviz(\n",
    "    clf,\n",
    "    out_file=None,\n",
    "    feature_names=colums,\n",
    "    class_names=[\"Passed\", \"Drop out\"],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True\n",
    ")\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"decision_tree\")  # Saves as 'decision_tree.pdf'\n",
    "#graph.view()  # Opens the tree\n",
    "\n",
    "report(train_df[colums].values.tolist(), train_df)\n",
    "print(\"----------------------------------\")\n",
    "report(test_df[colums].values.tolist(), test_df)"
   ],
   "id": "bb8decab0c8c7ee0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Metrics Report ===\n",
      "Accuracy: 0.9716\n",
      "AUC: 0.9981\n",
      "Precision (Class 0): 0.9433\n",
      "Recall (Class 0):    0.9868\n",
      "Precision (Class 1): 0.9912\n",
      "Recall (Class 1):    0.9618\n",
      "\n",
      "Full Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       910\n",
      "           1       0.99      0.96      0.98      1413\n",
      "\n",
      "    accuracy                           0.97      2323\n",
      "   macro avg       0.97      0.97      0.97      2323\n",
      "weighted avg       0.97      0.97      0.97      2323\n",
      "\n",
      "----------------------------------\n",
      "=== Metrics Report ===\n",
      "Accuracy: 0.8262\n",
      "AUC: 0.8353\n",
      "Precision (Class 0): 0.7716\n",
      "Recall (Class 0):    0.7885\n",
      "Precision (Class 1): 0.8625\n",
      "Recall (Class 1):    0.8503\n",
      "\n",
      "Full Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       227\n",
      "           1       0.86      0.85      0.86       354\n",
      "\n",
      "    accuracy                           0.83       581\n",
      "   macro avg       0.82      0.82      0.82       581\n",
      "weighted avg       0.83      0.83      0.83       581\n",
      "\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1fa60380cf7b2628",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
